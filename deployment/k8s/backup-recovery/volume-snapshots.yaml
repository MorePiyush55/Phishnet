# Volume Snapshot Configuration for Kubernetes

# VolumeSnapshotClass for Database Snapshots
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: phishnet-snapshot-class
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
spec:
  driver: ebs.csi.aws.com  # AWS EBS CSI driver
  deletionPolicy: Retain
  parameters:
    encrypted: "true"
    tagSpecification_1: "Key=Environment,Value=production"
    tagSpecification_2: "Key=Application,Value=phishnet"
    tagSpecification_3: "Key=Component,Value=database-snapshot"

---
# PostgreSQL Volume Snapshot CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-volume-snapshot
  namespace: phishnet
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
spec:
  schedule: "0 1 * * *"  # Daily at 1 AM UTC
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 2
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app.kubernetes.io/name: phishnet
            app.kubernetes.io/component: backup
        spec:
          serviceAccountName: snapshot-operator
          restartPolicy: OnFailure
          containers:
          - name: snapshot-creator
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              SNAPSHOT_NAME="postgres-snapshot-${TIMESTAMP}"
              
              echo "Creating volume snapshot: ${SNAPSHOT_NAME}"
              
              # Create VolumeSnapshot
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: ${SNAPSHOT_NAME}
                namespace: phishnet
                labels:
                  app.kubernetes.io/name: phishnet
                  app.kubernetes.io/component: database-snapshot
                  snapshot.date: $(date +%Y-%m-%d)
                annotations:
                  snapshot.kubernetes.io/created-by: "automated-backup"
                  snapshot.kubernetes.io/retention-days: "30"
              spec:
                volumeSnapshotClassName: phishnet-snapshot-class
                source:
                  persistentVolumeClaimName: postgres-data-postgres-0
              EOF
              
              # Wait for snapshot to be ready
              echo "Waiting for snapshot to be ready..."
              kubectl wait --for=condition=ReadyToUse volumesnapshot/${SNAPSHOT_NAME} -n phishnet --timeout=600s
              
              # Verify snapshot
              SNAPSHOT_SIZE=$(kubectl get volumesnapshot ${SNAPSHOT_NAME} -n phishnet -o jsonpath='{.status.restoreSize}')
              echo "Snapshot created successfully: ${SNAPSHOT_NAME}"
              echo "Snapshot size: ${SNAPSHOT_SIZE}"
              
              # Cleanup old snapshots (keep last 30 days)
              OLD_SNAPSHOTS=$(kubectl get volumesnapshots -n phishnet -l app.kubernetes.io/component=database-snapshot --sort-by=.metadata.creationTimestamp -o name | head -n -30)
              if [ ! -z "${OLD_SNAPSHOTS}" ]; then
                echo "Cleaning up old snapshots..."
                echo "${OLD_SNAPSHOTS}" | xargs -r kubectl delete -n phishnet
              fi
              
              echo "Volume snapshot process completed"
            resources:
              requests:
                memory: "64Mi"
                cpu: "50m"
              limits:
                memory: "128Mi"
                cpu: "100m"

---
# Redis Volume Snapshot CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: redis-volume-snapshot
  namespace: phishnet
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
spec:
  schedule: "15 1 * * *"  # Daily at 1:15 AM UTC
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 2
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app.kubernetes.io/name: phishnet
            app.kubernetes.io/component: backup
        spec:
          serviceAccountName: snapshot-operator
          restartPolicy: OnFailure
          containers:
          - name: snapshot-creator
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              
              TIMESTAMP=$(date +%Y%m%d-%H%M%S)
              SNAPSHOT_NAME="redis-snapshot-${TIMESTAMP}"
              
              echo "Creating Redis volume snapshot: ${SNAPSHOT_NAME}"
              
              # Create VolumeSnapshot
              cat <<EOF | kubectl apply -f -
              apiVersion: snapshot.storage.k8s.io/v1
              kind: VolumeSnapshot
              metadata:
                name: ${SNAPSHOT_NAME}
                namespace: phishnet
                labels:
                  app.kubernetes.io/name: phishnet
                  app.kubernetes.io/component: redis-snapshot
                  snapshot.date: $(date +%Y-%m-%d)
                annotations:
                  snapshot.kubernetes.io/created-by: "automated-backup"
                  snapshot.kubernetes.io/retention-days: "7"
              spec:
                volumeSnapshotClassName: phishnet-snapshot-class
                source:
                  persistentVolumeClaimName: redis-data-redis-0
              EOF
              
              # Wait for snapshot to be ready
              kubectl wait --for=condition=ReadyToUse volumesnapshot/${SNAPSHOT_NAME} -n phishnet --timeout=300s
              
              echo "Redis snapshot created successfully: ${SNAPSHOT_NAME}"
              
              # Cleanup old snapshots (keep last 7 days)
              OLD_SNAPSHOTS=$(kubectl get volumesnapshots -n phishnet -l app.kubernetes.io/component=redis-snapshot --sort-by=.metadata.creationTimestamp -o name | head -n -7)
              if [ ! -z "${OLD_SNAPSHOTS}" ]; then
                echo "Cleaning up old Redis snapshots..."
                echo "${OLD_SNAPSHOTS}" | xargs -r kubectl delete -n phishnet
              fi
            resources:
              requests:
                memory: "64Mi"
                cpu: "50m"
              limits:
                memory: "128Mi"
                cpu: "100m"

---
# ServiceAccount for Snapshot Operations
apiVersion: v1
kind: ServiceAccount
metadata:
  name: snapshot-operator
  namespace: phishnet
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup

---
# ClusterRole for Snapshot Operations
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: snapshot-operator
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
rules:
- apiGroups: ["snapshot.storage.k8s.io"]
  resources: ["volumesnapshots", "volumesnapshotclasses"]
  verbs: ["get", "list", "create", "delete", "watch"]
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "list"]
- apiGroups: ["storage.k8s.io"]
  resources: ["storageclasses"]
  verbs: ["get", "list"]

---
# ClusterRoleBinding for Snapshot Operations
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: snapshot-operator
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
subjects:
- kind: ServiceAccount
  name: snapshot-operator
  namespace: phishnet
roleRef:
  kind: ClusterRole
  name: snapshot-operator
  apiGroup: rbac.authorization.k8s.io

---
# AWS Backup Credentials Secret (Template)
apiVersion: v1
kind: Secret
metadata:
  name: aws-backup-credentials
  namespace: phishnet
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
type: Opaque
stringData:
  credentials: |
    [default]
    aws_access_key_id = YOUR_ACCESS_KEY_ID
    aws_secret_access_key = YOUR_SECRET_ACCESS_KEY
  config: |
    [default]
    region = us-east-1
    output = json
    
---
# Backup Monitoring ServiceMonitor for Prometheus
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: backup-monitoring
  namespace: phishnet
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
spec:
  selector:
    matchLabels:
      app.kubernetes.io/component: backup
  endpoints:
  - port: metrics
    interval: 60s
    path: /metrics
    
---
# Backup Alerts for Prometheus
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: backup-alerts
  namespace: phishnet
  labels:
    app.kubernetes.io/name: phishnet
    app.kubernetes.io/component: backup
spec:
  groups:
  - name: backup.rules
    rules:
    - alert: BackupJobFailed
      expr: kube_job_status_failed{job_name=~".*backup.*"} > 0
      for: 5m
      labels:
        severity: critical
        component: backup
      annotations:
        summary: "Backup job failed"
        description: "Backup job {{ $labels.job_name }} in namespace {{ $labels.namespace }} has failed"
        
    - alert: BackupJobTooOld
      expr: time() - kube_job_status_start_time{job_name=~".*backup.*"} > 86400
      for: 5m
      labels:
        severity: warning
        component: backup
      annotations:
        summary: "Backup job is too old"
        description: "Last successful backup for {{ $labels.job_name }} was more than 24 hours ago"
        
    - alert: VolumeSnapshotFailed
      expr: kube_volumesnapshot_status_ready_to_use == 0
      for: 10m
      labels:
        severity: critical
        component: backup
      annotations:
        summary: "Volume snapshot failed"
        description: "Volume snapshot {{ $labels.volumesnapshot }} in namespace {{ $labels.namespace }} is not ready"
